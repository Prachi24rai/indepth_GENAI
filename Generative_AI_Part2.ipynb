{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **PART 2 GENERATIVE AI**"
      ],
      "metadata": {
        "id": "gM-bisxU_Kkw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "What is generative AI? Everything you need to know"
      ],
      "metadata": {
        "id": "J1MaclPN_TLz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generative AI is a type of artificial intelligence technology that can produce various types of content, including text, imagery, audio and synthetic data."
      ],
      "metadata": {
        "id": "GHFHAKYq_Uda"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The technology, it should be noted, is not brand-new. Generative AI was introduced in the 1960s in chatbots. But it was not until 2014, with the introduction of generative adversarial networks, or GANs -- a type of machine learning algorithm -- that generative AI could create convincingly authentic images, videos and audio of real people."
      ],
      "metadata": {
        "id": "jNOR0-mp_fcB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Two additional recent advances that will be discussed in more detail below have played a critical part in generative AI going mainstream: transformers and the breakthrough language models they enabled.***"
      ],
      "metadata": {
        "id": "AAuNJTgb_gPn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transformers are a type of machine learning that made it possible for researchers to train ever-larger models without having to label all of the data in advance. New models could thus be trained on billions of pages of text, resulting in answers with more depth. In addition, transformers unlocked a new notion called attention that enabled models to track the connections between words across pages, chapters and books rather than just in individual sentences. And not just words: Transformers could also use their ability to track connections to analyze code, proteins, chemicals and DNA."
      ],
      "metadata": {
        "id": "qvH36ChV_tvz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "large language models (LLMs) -- i.e., models with billions or even trillions of parameters -- have opened a new era in which generative AI models can write engaging text, paint photorealistic images and even create somewhat entertaining sitcoms on the fly. Moreover, innovations in multimodal AI enable teams to generate content across multiple types of media, including text, graphics and video. This is the basis for tools like Dall-E that automatically create images from a text description or generate text captions from images."
      ],
      "metadata": {
        "id": "ncAOcIL8ALxB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **How does generative AI work?**"
      ],
      "metadata": {
        "id": "koB6ocaFATlR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generative AI starts with a prompt that could be in the form of a text, an image, a video, a design, musical notes, or any input that the AI system can process. Various AI algorithms then return new content in response to the prompt. Content can include essays, solutions to problems, or realistic fakes created from pictures or audio of a person.\n",
        "\n",
        "Early versions of generative AI required submitting data via an API or an otherwise complicated process. Developers had to familiarize themselves with special tools and write applications using languages such as Python.\n",
        "\n",
        "Now, pioneers in generative AI are developing better user experiences that let you describe a request in plain language. After an initial response, you can also customize the results with feedback about the style, tone and other elements you want the generated content to reflect."
      ],
      "metadata": {
        "id": "1fv-6mi2Av3L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Generative AI models***"
      ],
      "metadata": {
        "id": "Tse4WSYOFKr2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generative AI models\n",
        "Generative AI models combine various AI algorithms to represent and process content. For example, to generate text, various natural language processing techniques transform raw characters (e.g., letters, punctuation and words) into sentences, parts of speech, entities and actions, which are represented as vectors using multiple encoding techniques. Similarly, images are transformed into various visual elements, also expressed as vectors. One caution is that these techniques can also encode the biases, racism, deception and puffery contained in the training data.\n",
        "\n",
        "Once developers settle on a way to represent the world, they apply a particular neural network to generate new content in response to a query or prompt. Techniques such as GANs and variational autoencoders (VAEs) -- neural networks with a decoder and encoder -- are suitable for generating realistic human faces, synthetic data for AI training or even facsimiles of particular humans.\n",
        "\n",
        "Recent progress in transformers such as Google's Bidirectional Encoder Representations from Transformers (BERT), OpenAI's GPT and Google AlphaFold have also resulted in neural networks that can not only encode language, images and proteins but also generate new content."
      ],
      "metadata": {
        "id": "KEI-5HktFb57"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **What are Dall-E, ChatGPT and Bard?**"
      ],
      "metadata": {
        "id": "NMth6bMJGntC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Dall-E. ***Trained on a large data set of images and their associated text descriptions, Dall-E is an example of a multimodal AI application that identifies connections across multiple media, such as vision, text and audio. In this case, it connects the meaning of words to visual elements. It was built using OpenAI's GPT implementation in 2021. Dall-E 2, a second, more capable version, was released in 2022. It enables users to generate imagery in multiple styles driven by user prompts."
      ],
      "metadata": {
        "id": "d1e6w6A1Gqle"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***ChatGPT. ***The AI-powered chatbot that took the world by storm in November 2022 was built on OpenAI's GPT-3.5 implementation. OpenAI has provided a way to interact and fine-tune text responses via a chat interface with interactive feedback. Earlier versions of GPT were only accessible via an API. GPT-4 was released March 14, 2023. ChatGPT incorporates the history of its conversation with a user into its results, simulating a real conversation."
      ],
      "metadata": {
        "id": "QpJz1ohGG8DD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Bard. ***Google was another early leader in pioneering transformer AI techniques for processing language, proteins and other types of content. It open sourced some of these models for researchers. However, it never released a public interface for these models. Microsoft's decision to implement GPT into Bing drove Google to rush to market a public-facing chatbot, Google Bard, built on a lightweight version of its LaMDA family of large language models. Google suffered a significant loss in stock price following Bard's rushed debut after the language model incorrectly said the Webb telescope was the first to discover a planet in a foreign solar system."
      ],
      "metadata": {
        "id": "k7sZ_LdVHEE7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***What are use cases for generative AI?***\n"
      ],
      "metadata": {
        "id": "Wm879BydHp9Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generative AI can be applied in various use cases to generate virtually any kind of content. The technology is becoming more accessible to users of all kinds thanks to cutting-edge breakthroughs like GPT that can be tuned for different applications. Some of the use cases for generative AI include the following:\n",
        "\n",
        "Implementing chatbots for customer service and technical support.\n",
        "Deploying deepfakes for mimicking people or even specific individuals.\n",
        "Improving dubbing for movies and educational content in different languages.\n",
        "Writing email responses, dating profiles, resumes and term papers.\n",
        "Creating photorealistic art in a particular style.\n",
        "Improving product demonstration videos.\n",
        "Suggesting new drug compounds to test.\n",
        "Designing physical products and buildings.\n",
        "Optimizing new chip designs.\n",
        "Writing music in a specific style or tone."
      ],
      "metadata": {
        "id": "VmXoFThbUYUc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***What are the benefits of generative AI?***\n"
      ],
      "metadata": {
        "id": "bkkoOLXwUisR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generative AI can be applied extensively across many areas of the business. It can make it easier to interpret and understand existing content and automatically create new content. Developers are exploring ways that generative AI can improve existing workflows, with an eye to adapting workflows entirely to take advantage of the technology. Some of the potential benefits of implementing generative AI include the following:\n",
        "\n",
        "Automating the manual process of writing content.\n",
        "Reducing the effort of responding to emails.\n",
        "Improving the response to specific technical queries.\n",
        "Creating realistic representations of people.\n",
        "Summarizing complex information into a coherent narrative.\n",
        "Simplifying the process of creating content in a particular style."
      ],
      "metadata": {
        "id": "NeAlC3irU_GJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***What are the limitations of generative AI?***\n"
      ],
      "metadata": {
        "id": "9kSe-v0nVHrN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Early implementations of generative AI vividly illustrate its many limitations. Some of the challenges generative AI presents result from the specific approaches used to implement particular use cases. For example, a summary of a complex topic is easier to read than an explanation that includes various sources supporting key points. The readability of the summary, however, comes at the expense of a user being able to vet where the information comes from.\n",
        "\n",
        "Here are some of the limitations to consider when implementing or using a generative AI app:\n",
        "\n",
        "It does not always identify the source of content.\n",
        "It can be challenging to assess the bias of original sources.\n",
        "Realistic-sounding content makes it harder to identify inaccurate information.\n",
        "It can be difficult to understand how to tune for new circumstances.\n",
        "Results can gloss over bias, prejudice and hatred."
      ],
      "metadata": {
        "id": "Ru9_GucHV1jF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "0tEXB96MV2aZ"
      }
    }
  ]
}